{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LeetCode SQL Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "175. Combine Two Tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to report the first name, last name, city, and state of each person in the Person table. If the address of a personId is not present in the Address table, report null instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN\n",
    "select firstName, lastName, city, state\n",
    "from person left join address on person.personId = address.personId"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN\n",
    "import pandas as pd\n",
    "def combine_two_tables(person: pd.DataFrame, address: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_merge = person.merge(address, on='personId', how='left')\n",
    "    return df_merge[['firstName', 'lastName', 'city', 'state']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark\n",
    "result = person.join(address, person.personId == address.personId, 'left')\n",
    "result = result.select('firstName', 'lastName', 'city', 'state')\n",
    "result.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "181. Employees Earning More Than Their Managers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the employees who earn more than their managers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF JOIN\n",
    "select e1.name as Employee\n",
    "from employee e1 inner join employee e2 on e1.managerid = e2.id\n",
    "where e1.salary > e2.salary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# INNER JOIN\n",
    "def find_employees(employee: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_merge = employee.merge(employee, left_on='id', right_on='managerId', how='inner')\n",
    "    df_filter = df_merge[df_merge['salary_y'] > df_merge['salary_x']]['name_y']\n",
    "    return pd.DataFrame({'Employee':df_filter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark\n",
    "from pyspark.sql import function as F\n",
    "\n",
    "employee_name = (\n",
    "    employee.alias('e1').join(employee.alias(e2), F.col('e1.managerId') == F.col('e2.id')).filter(F.col('e1.salary') > F.col('e2.salary')).select(F.col('e1.name').alias('Employee'))\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "182. Duplicate Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to report all the duplicate emails. Note that it's guaranteed that the email field is not NULL.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY\n",
    "select email\n",
    "from person\n",
    "group by email\n",
    "having count(email) > 1\n",
    "\n",
    "# CTE, ROW_NUMBER, PARTITION\n",
    "with cte as (\n",
    "select email, row_number() over(partition by email order by email) as rn\n",
    "from person)\n",
    "select distinct(email)\n",
    "from cte\n",
    "where rn>1\n",
    "\n",
    "# SUB-QUERY, ROW_NUMBER, PARTITION\n",
    "select email from (\n",
    "select email, row_number() over(partition by email order by email) as rn\n",
    "from person) as sq\n",
    "where rn>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark = GROUBY\n",
    "email_count = person.groupBy('email').count()\n",
    "duplicate_emails = email_count.filter(email_count['count']>1).select('email')\n",
    "return duplicate_emails\n",
    "\n",
    "# PySpark = ROW_NUMBER\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.functions import row_number\n",
    "window_spec = Window.partitionBy(\"email\").orderBy(\"email\")\n",
    "person_with_rn = person.withColumn(\"rn\", row_number().over(window_spec))\n",
    "result = person_with_rn.filter(person_with_rn.rn > 1)\n",
    "return result.select(\"email\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUPBY\n",
    "def duplicate_emails(person: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_group = person.groupby('email').agg(email_count=('email', 'count')).reset_index()\n",
    "    df_filter = df_group[df_group['email_count'] > 1]['email']\n",
    "    return pd.DataFrame({'Email':df_filter})\n",
    "\n",
    "# ROW_NUMBER - cumcount()\n",
    "def duplicate_emails(person: pd.DataFrame) -> pd.DataFrame:\n",
    "    person['email_count'] = person.groupby('email').cumcount() + 1\n",
    "    df_filter = person[person['email_count'] > 1]['email'].drop_duplicates()\n",
    "    return pd.DataFrame({'Email':df_filter})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark\n",
    "person_sorted = person.orderBy('id')\n",
    "person_unique = person_sorted.dropDuplicates(['email'])\n",
    "return person_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "183. Customers Who Never Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find all customers who never order anything.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN\n",
    "select customers.name as Customers\n",
    "from customers left join orders on customers.id = orders.customerId\n",
    "where customerId is NULL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN & .isnull()\n",
    "def find_customers(customers: pd.DataFrame, orders: pd.DataFrame) -> pd.DataFrame:\n",
    "    df_merge = customers.merge(orders, left_on='id', right_on='customerId', how='left')\n",
    "    df_filter_null = df_merge[df_merge['customerId'].isnull()]['name']\n",
    "    return pd.DataFrame({'Customers':df_filter_null})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PySpark\n",
    "join_df = customers.join(orders, customers.id == orders.customerId, 'left')\n",
    "no_orders = join_df.filter(col('customerId'.isNull()))\n",
    "result = no_order.select(customers['name'].alias('Customers'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "196. Delete Duplicate Emails"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to delete all duplicate emails, keeping only one unique email with the smallest id.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DELETE\n",
    "delete p1\n",
    "from person p1, person p2\n",
    "where p1.email = p2.email and p1.id > p2.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort_values() & drop_duplicates()\n",
    "def delete_duplicate_emails(person: pd.DataFrame) -> None:\n",
    "    person.sort_values(by='id', inplace=True)\n",
    "    person.drop_duplicates(subset='email', keep='first', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "197. Rising Temperature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find all dates' id with higher temperatures compared to its previous dates (yesterday).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN ON DATEDIFF\n",
    "select w2.id\n",
    "from weather w1 left join weather w2 on datediff(day, w1.recordDate, w2.recordDate) = 1\n",
    "where w2.temperature > w1.temperature \n",
    "\n",
    "# WINDOW - LAG - PERFORMANCE OPTIMIZED FOR ROW BY ROW OPERATIONS IN REAL WORLD\n",
    "with cte as (\n",
    "select id, recorddate, temperature, lag(recorddate, 1) over (order by recorddate) as prevdate, lag(temperature, 1) over (order by recorddate) as prevdaytemp\n",
    "from weather)\n",
    "select id\n",
    "from cte\n",
    "where temperature > prevdaytemp and datediff(day, prevdate, recorddate) = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LAG - shift(1)\n",
    "def rising_temperature(weather: pd.DataFrame) -> pd.DataFrame:\n",
    "    weather['prev_date'] = weather['recordDate'].shift(1) \n",
    "    weather['prev_day_temp'] = weather['temperature'].shift(1)\n",
    "    df_filter = weather[weather['temperature'] > weather['prev_day_temp']]['id']\n",
    "    return pd.DataFrame({'id':df_filter})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "511. Game Play Analysis I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the first login date for each player.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROW NUMBER\n",
    "with cte as (\n",
    "select *, row_number() over(partition by player_id order by event_date) as rn\n",
    "from activity)\n",
    "select player_id, event_date as first_login\n",
    "from cte\n",
    "where rn = 1\n",
    "\n",
    "# MIN\n",
    "select player_id, min(event_date) as first_login\n",
    "from activity\n",
    "group by player_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "577. Employee Bonus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to report the name and bonus amount of each employee with a bonus less than 1000.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEFT JOIN\n",
    "select name, bonus\n",
    "from employee e left join bonus b on e.empId = b.empId\n",
    "where bonus < 1000 or bonus is null "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "584. Find Customer Referee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the names of the customer that are not referred by the customer with id = 2.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !=\n",
    "select name\n",
    "from customer\n",
    "where referee_id != 2 or referee_id is null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "586. Customer Placing the Largest Number of Orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the customer_number for the customer who has placed the largest number of orders.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TOP & ORDER BY\n",
    "select top 1 customer_number\n",
    "from orders\n",
    "group by customer_number\n",
    "order by count(customer_number) desc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "595. Big Countries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the name, population, and area of the big countries.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# WHERE\n",
    "select name, population, area\n",
    "from world\n",
    "where area >= 3000000 or population >= 25000000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "596. Classes More Than 5 Students"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find all the classes that have at least five students.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GROUP BY AND HAVING\n",
    "select class\n",
    "from courses\n",
    "group by class\n",
    "having count(class) >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "607. Sales Person\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the names of all the salespersons who did not have any orders related to the company with the name \"RED\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JUST JOIN\n",
    "SELECT s.name\n",
    "FROM salesperson s\n",
    "LEFT JOIN orders o ON s.sales_id = o.sales_id\n",
    "LEFT JOIN company c ON o.com_id = c.com_id AND c.name = 'RED'\n",
    "WHERE c.com_id IS NULL;\n",
    "\n",
    "# CTE\n",
    "WITH cte AS (\n",
    "  SELECT s.name\n",
    "  FROM salesperson s\n",
    "  LEFT JOIN orders o ON s.sales_id = o.sales_id\n",
    "  LEFT JOIN company c ON o.com_id = c.com_id\n",
    "  WHERE c.name = 'RED' AND s.name IS NOT NULL\n",
    ")\n",
    "SELECT name\n",
    "FROM salesperson\n",
    "WHERE name NOT IN (SELECT name FROM cte);\n",
    "\n",
    "# SUB QUERY\n",
    "SELECT s.name\n",
    "FROM salesperson s\n",
    "WHERE NOT EXISTS (\n",
    "  SELECT 1\n",
    "  FROM orders o\n",
    "  JOIN company c ON o.com_id = c.com_id\n",
    "  WHERE o.sales_id = s.sales_id AND c.name = 'RED'\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "610. Triangle Judgement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Report for every three line segments whether they can form a triangle.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE STATEMENT\n",
    "select x, y, z, \n",
    "case \n",
    "when x+y>z and x+z>y and y+z>x then 'Yes'\n",
    "else 'No'\n",
    "end as Triangle\n",
    "from triangle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "619. Biggest Single Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single number is a number that appeared only once in the MyNumbers table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXTRACT THE SINGLE NUMBERS FIRST AND THEN GET MAX FROM IT\n",
    "select max(num) as num\n",
    "from (\n",
    "    select num\n",
    "    from MyNumbers\n",
    "    group by num\n",
    "    having count(num) < 2\n",
    ") as sq\n",
    "\n",
    "# WITHOUT SUBQUERY\n",
    "SELECT MAX(num) AS num\n",
    "FROM MyNumbers\n",
    "GROUP BY num\n",
    "HAVING COUNT(num) < 2;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1661. Average Time of Process per Machine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a factory website that has several machines each running the same number of processes. Write a solution to find the average time each machine takes to complete a process.\n",
    "\n",
    "The time to complete a process is the 'end' timestamp minus the 'start' timestamp. The average time is calculated by the total time to complete every process on the machine divided by the number of processes that were run.\n",
    "\n",
    "The resulting table should have the machine_id along with the average time as processing_time, which should be rounded to 3 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF JOIN\n",
    "select a.machine_id, ROUND(AVG(b.timestamp - a.timestamp),3) as processing_time\n",
    "from activity a inner join activity b\n",
    "on a.machine_id = b.machine_id and a.process_id = b.process_id and a.activity_type = 'start' and b.activity_type = 'end'\n",
    "group by a.machine_id\n",
    "\n",
    "# LAG\n",
    "with cte as (\n",
    "    select *, lag(timestamp, 1) over(partition by machine_id, process_id order by machine_id) as prev_timestamp\n",
    "    from activity\n",
    ")\n",
    "select machine_id, AVG(timestamp - prev_timestamp) as processing_time\n",
    "from cte\n",
    "where activity_type = 'end'\n",
    "group by machine_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1280. Students and Examinations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the number of times each student attended each exam.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CROSS JOIN\n",
    "with cte as (\n",
    "select *\n",
    "from students st cross join subjects su)\n",
    "\n",
    "select c.student_id, c.student_name, c.subject_name, count(e.subject_name) as attended_exams\n",
    "from cte c left join examinations e on c.student_id = e.student_id and c.subject_name = e.subject_name\n",
    "group by c.student_id, c.student_name, c.subject_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "570. Managers with at Least 5 Direct Reports"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find managers with at least five direct reports.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SELF and GROUP BY HAVING\n",
    "select e2.name\n",
    "from employee e1 left join employee e2\n",
    "on e1.managerId = e2.id\n",
    "group by e2.id, e2.name  # Look closely here\n",
    "having count(e2.id) >= 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1934. Confirmation Rate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the confirmation rate of each user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CASE\n",
    "select s.user_id, ROUND(AVG(case when c.action = 'confirmed' then 1.0 else 0.0 end), 2) as confirmation_rate\n",
    "from signups s left join confirmations c\n",
    "on s.user_id = c.user_id\n",
    "group by s.user_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1251. Average Selling Price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the average selling price for each product. average_price should be rounded to 2 decimal places. If a product does not have any sold units, its average selling price is assumed to be 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# JOIN and JOIN Conditions\n",
    "select p.product_id, COALESCE(ROUND(SUM(u.units * p.price * 1.0)/SUM(u.units * 1.0),2), 0) as average_price\n",
    "from prices p left join unitssold u \n",
    "on p.product_id = u.product_id and u.purchase_date >= p.start_date and u.purchase_date <= p.end_date\n",
    "group by p.product_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1075. Project Employees I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an SQL query that reports the average experience years of all the employees for each project, rounded to 2 digits.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AVG and GROUP BY\n",
    "select p.project_id, round(sum(e.experience_years*1.0)/count(*),2) as average_years\n",
    "from project p left join employee e\n",
    "on p.employee_id = e.employee_id\n",
    "group by project_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1633. Percentage of Users Attended a Contest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the percentage of the users registered in each contest rounded to two decimals.\n",
    "\n",
    "Return the result table ordered by percentage in descending order. In case of a tie, order it by contest_id in ascending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Without Join\n",
    "SELECT  r.contest_id, ROUND(COUNT(DISTINCT r.user_id) * 100.0 / (SELECT COUNT(DISTINCT user_id) FROM users), 2) AS percentage\n",
    "FROM register r\n",
    "GROUP BY r.contest_id\n",
    "ORDER BY percentage DESC, contest_id ASC;\n",
    "\n",
    "# Cross Join\n",
    "select r.contest_id, round(count(distinct r.user_id)*100.0/count(distinct u.user_id), 2) as percentage\n",
    "from users u \n",
    "cross join register r\n",
    "group by r.contest_id\n",
    "order by percentage desc, contest_id asc\n",
    "\n",
    "# Precomputing the unique count\n",
    "DECLARE @total_users_count INT;\n",
    "SELECT @total_users_count = COUNT(DISTINCT user_id) FROM users;\n",
    "SELECT r.contest_id, ROUND(COUNT(DISTINCT r.user_id) * 100.0 / @total_users_count, 2) AS percentage\n",
    "FROM register r\n",
    "GROUP BY r.contest_id\n",
    "ORDER BY percentage DESC, contest_id ASC;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1211. Queries Quality and Percentage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define query quality as:\n",
    "\n",
    "The average of the ratio between query rating and its position.\n",
    "\n",
    "We also define poor query percentage as:\n",
    "\n",
    "The percentage of all queries with rating less than 3.\n",
    "\n",
    "Write a solution to find each query_name, the quality and poor_query_percentage.\n",
    "\n",
    "Both quality and poor_query_percentage should be rounded to 2 decimal places."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Case, When there is need to insert select statement to get a new column and group by it, think of if you can use CASE \n",
    "SELECT \n",
    "query_name,\n",
    "ROUND(SUM(rating*1.0/position) / COUNT(*),2) as quality,\n",
    "ROUND(SUM(CASE WHEN rating<3 THEN 1 ELSE 0 END)*100.0 / COUNT(*),2) as poor_query_percentage\n",
    "FROM queries\n",
    "GROUP BY query_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1193. Monthly Transactions I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write an SQL query to find for each month and country, the number of transactions and their total amount, the number of approved transactions and their total amount.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATE and CASE\n",
    "select \n",
    "FORMAT(trans_date, 'yyyy-MM') as month, \n",
    "country,\n",
    "count(FORMAT(trans_date, 'yyyy-MM')) as trans_count,\n",
    "sum(case when state = 'approved' then 1 else 0 end) as approved_count,\n",
    "sum(amount) as trans_total_amount,\n",
    "sum(case when state = 'approved' then amount else 0 end) as approved_total_amount\n",
    "from transactions\n",
    "group by FORMAT(trans_date, 'yyyy-MM'), country"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1174. Immediate Food Delivery II"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the customer's preferred delivery date is the same as the order date, then the order is called immediate; otherwise, it is called scheduled.\n",
    "\n",
    "The first order of a customer is the order with the earliest order date that the customer made. It is guaranteed that a customer has precisely one first order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTE and CASE\n",
    "with cte as (\n",
    "select *, row_number() over(partition by customer_id order by order_date) as rn\n",
    "from delivery)\n",
    "\n",
    "SELECT ROUND((sum(CASE WHEN order_date = customer_pref_delivery_date THEN 1.0 ELSE 0.0 END) * 1.0 / COUNT(*))*100, 2) AS immediate_percentage\n",
    "FROM cte\n",
    "where rn = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "550. Game Play Analysis IV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to report the fraction of players that logged in again on the day after the day they first logged in, rounded to 2 decimal places. In other words, you need to count the number of players that logged in for at least two consecutive days starting from their first login date, then divide that number by the total number of players.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTE, DATEDIFF\n",
    "with cte as (\n",
    "    select player_id, min(event_date) as all_players_min_date\n",
    "    from activity\n",
    "    group by player_id\n",
    ")\n",
    "\n",
    "select round(count(a.player_id)*1.0/count(c.player_id), 2) as fraction\n",
    "from cte c left join activity a\n",
    "on c.player_id = a.player_id and datediff(day, c.all_players_min_date, a.event_date) = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1141. User Activity for the Past 30 Days I"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to find the daily active user count for a period of 30 days ending 2019-07-27 inclusively. A user was active on someday if they made at least one activity on that day.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Between is inclusive and you can use dateadd -30\n",
    "select activity_date as day, count(distinct user_id) as active_users\n",
    "from activity\n",
    "where activity_date > dateadd(day, -30, '2019-07-27') and activity_date <= '2019-07-27'\n",
    "group by activity_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1070. Product Sales Analysis III"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to select the product id, year, quantity, and price for the first year of every product sold.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Approach 2;  Using CTE\n",
    "with cte as (\n",
    "    select product_id, min(year) as min_year\n",
    "    from sales\n",
    "    group by product_id\n",
    ")\n",
    "select c.product_id, c.min_year as first_year, s.quantity, s.price\n",
    "from cte c inner join sales s\n",
    "on c.product_id = s.product_id and c.min_year = s.year\n",
    "\n",
    "\n",
    "#Approach 2;  Using IN\n",
    "SELECT product_id, year AS first_year, quantity, price\n",
    "FROM Sales\n",
    "WHERE (product_id, year) in (\n",
    "    SELECT product_id, MIN(year) \n",
    "    FROM Sales\n",
    "    GROUP BY product_id\n",
    ")\n",
    "\n",
    "#Approach 3 : Using Except\n",
    "SELECT product_id, year AS first_year, quantity, price\n",
    "FROM Sales\n",
    "EXCEPT\n",
    "SELECT s1.product_id, s1.year, s1.quantity, s1.price\n",
    "FROM Sales s1\n",
    "JOIN Sales s2 ON s1.product_id = s2.product_id AND s1.year > s2.year;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "619. Biggest Single Number"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A single number is a number that appeared only once in the MyNumbers table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CTE and MAX\n",
    "with cte as (\n",
    "    select num, count(num) as cnt\n",
    "    from mynumbers\n",
    "    group by num\n",
    "    having count(num) = 1)\n",
    "select max(num) as num\n",
    "from cte\n",
    "\n",
    "# ORDER BY DESC and TOP 1\n",
    "SELECT coalesce ((\n",
    "    SELECT top 1 num\n",
    "FROM mynumbers\n",
    "GROUP BY num\n",
    "HAVING COUNT(*) = 1\n",
    "ORDER BY num desc), null) as num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Customers Who Bought All Products\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a solution to report the customer ids from the Customer table that bought all the products in the Product table.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Precompute\n",
    "DECLARE @distinct_products INT;\n",
    "SELECT @distinct_products = COUNT(product_key) from product\n",
    "\n",
    "select customer_id\n",
    "from customer\n",
    "group by customer_id\n",
    "having count(distinct product_key) = @distinct_products"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1731. The Number of Employees Which Report to Each Employee"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this problem, we will consider a manager an employee who has at least 1 other employee reporting to them.\n",
    "\n",
    "Write a solution to report the ids and the names of all managers, the number of employees who report directly to them, and the average age of the reports rounded to the nearest integer.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SELECT e1.employee_id, e1.name, COUNT(e2.employee_id) as reports_count, ROUND(AVG(e2.age*1.0),0) as average_age\n",
    "FROM employees e1\n",
    "INNER JOIN employees e2 ON e1.employee_id = e2.reports_to\n",
    "GROUP BY e1.employee_id, e1.name\n",
    "ORDER BY employee_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Notes:\n",
    "\n",
    "* Finding Duplicate Rows\n",
    "  * GROUP BY and HAVING COUNT > 1,  \n",
    "  * CTE, ROW_NUMBER, PARTITION\n",
    "  * SUBQUERY, ROW_NUMBER, PARTITION\n",
    "\n",
    "* Finding Duplicate Rows From Two Columns\n",
    "  * DISTINCT\n",
    "  \n",
    "* Customers who never ordered anything\n",
    "  * SUBQUERY\n",
    "  * JOIN and Filter NULL\n",
    "* Decimal Places\n",
    "  * COL*1.0 instead of casting into decimal\n",
    "  * cast (col) as decimal(10,2)\n",
    "  * Cast (col) as float and then ROUND(col, 2)\n",
    "* Finding Consecutive\n",
    "  * Use JOIN based on condition col+1 = 1 or col-1=1 and where value is 1\n",
    "  * LAG and LEAD\n",
    "* Salesperson who did not have any orders with a company\n",
    "  * Find the names and then do not in subquery\n",
    "* Compare with all the items\n",
    "  * Cross join\n",
    "* Iff \n",
    "  * Update salary set sex = iff(sex=’f’, ‘m’, ‘f’)\n",
    "  * Use CASE WHEN THEN END\n",
    "* Count of 2 different columns together\n",
    "  * Use group by for two different columns and in having put any other third column apart from these 2\n",
    "  * We don't need to just use the two columns in select to put the inside count.\n",
    "* Dates:\n",
    "  * Use MIN and MAX for Dates\n",
    "  * BETWEEN is Inclusive - (where activity_date between ‘small_date’ and ‘big_date’)\n",
    "  * datediff(day, today, previousdate)\n",
    "  * dateadd(day, -1, date)\n",
    "* HANDLING NULLS\n",
    "  * Return the specified value IF the expression is NULL, otherwise return the expression:\n",
    "    * SELECT ISNULL(NULL, 'W3Schools.com');\n",
    "  * Compare two expressions:\n",
    "    * SELECT NULLIF(25, 25);\n",
    "* Comparing two side by side columsn\n",
    "  * CASE\n",
    "* Pivot\n",
    "  * USE PIVOT\n",
    "  * Or CASE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SQL Commands\n",
    "\n",
    "* Retrieves specific columns from a table  \n",
    "  SQL Command: `SELECT column1, column2 FROM table_name`\n",
    "\n",
    "* Retrieves all columns from a table where a specified condition is met  \n",
    "  SQL Command: `SELECT * FROM table_name WHERE condition`\n",
    "\n",
    "* Counts the number of rows for each group of a specified column  \n",
    "  SQL Command: `SELECT column1, COUNT(*) FROM table_name GROUP BY column1`\n",
    "\n",
    "* Joins two tables based on a common column and retrieves all columns  \n",
    "  SQL Command: `SELECT * FROM table1 JOIN table2 ON table1.column = table2.column`\n",
    "\n",
    "* Retrieves all columns from a table and sorts the results in ascending order  \n",
    "  SQL Command: `SELECT * FROM table_name ORDER BY column ASC`\n",
    "\n",
    "* Creates or replaces a temporary view from a table  \n",
    "  SQL Command: `CREATE OR REPLACE TEMP VIEW view_name AS SELECT * FROM table_name`\n",
    "\n",
    "* Retrieves all columns from a view where a specified condition is met  \n",
    "  SQL Command: `SELECT * FROM view_name WHERE condition`\n",
    "\n",
    "* Inserts new data into specified columns of a table  \n",
    "  SQL Command: `INSERT INTO table_name (column1, column2) VALUES (value1, value2)`\n",
    "\n",
    "* Retrieves all columns from a table  \n",
    "  SQL Command: `SELECT * FROM table_name`\n",
    "\n",
    "* Counts the total number of rows in a table  \n",
    "  SQL Command: `SELECT COUNT(*) FROM table_name`\n",
    "\n",
    "* Retrieves distinct combinations of specified columns from a table  \n",
    "  SQL Command: `SELECT DISTINCT column1, column2 FROM table_name`\n",
    "\n",
    "* Calculates the average of a column grouped by another column  \n",
    "  SQL Command: `SELECT column1, AVG(column2) FROM table_name GROUP BY column1`\n",
    "\n",
    "* Renames a column in the result set  \n",
    "  SQL Command: `SELECT column1 AS new_column_name FROM table_name`\n",
    "\n",
    "* Retrieves the first 10 rows from a table  \n",
    "  SQL Command: `SELECT * FROM table_name LIMIT 10`\n",
    "\n",
    "* Calculates the sum of a specified column in a table  \n",
    "  SQL Command: `SELECT SUM(column1) FROM table_name`\n",
    "\n",
    "* Retrieves all columns from a table  \n",
    "  SQL Command: `SELECT * FROM table_name`\n",
    "\n",
    "* Retrieves rows where a specified column is NULL or NOT NULL  \n",
    "  SQL Command: `SELECT column1 FROM table_name WHERE column2 IS NULL/NOT NULL`\n",
    "\n",
    "* Retrieves rows where a column's value is greater than or equal to a specified value  \n",
    "  SQL Command: `SELECT * FROM table_name WHERE column >= value`\n",
    "\n",
    "* Retrieves rows where a column's value matches any in a list of values  \n",
    "  SQL Command: `SELECT * FROM table_name WHERE column IN (value1, value2)`\n",
    "\n",
    "* Retrieves rows where a column's value is within a specified range  \n",
    "  SQL Command: `SELECT * FROM table_name WHERE column BETWEEN value1 AND value2`\n",
    "\n",
    "* Retrieves rows where a column matches a specified pattern  \n",
    "  SQL Command: `SELECT * FROM table_name WHERE column LIKE 'pattern'`\n",
    "\n",
    "* Converts a column's data type to a specified type  \n",
    "  SQL Command: `SELECT CAST(column AS data_type) FROM table_name`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas Commands\n",
    "\n",
    "* Select a single column from the DataFrame:  \n",
    "  `df['column1']`\n",
    "\n",
    "* Select multiple columns:  \n",
    "  `df[['column1', 'column2']]`\n",
    "\n",
    "* Filter rows where the condition is true:  \n",
    "  `df[df['column'] > value]`\n",
    "\n",
    "* Group by one column and sum values of another column:  \n",
    "  `df.groupby('column1')['column2'].sum()`\n",
    "\n",
    "* Group by one column and calculate an aggregate (e.g., mean):  \n",
    "  `df.groupby('column1').agg({'column2': 'mean'})`\n",
    "\n",
    "* Merge two DataFrames on a common column:  \n",
    "  `df1.merge(df2, on='column', how='inner')`\n",
    "\n",
    "* Sort the DataFrame by a column:  \n",
    "  `df.sort_values(by='column', ascending=False)`\n",
    "\n",
    "* Remove duplicate rows based on specific columns:  \n",
    "  `df.drop_duplicates(subset=['column1', 'column2'])`\n",
    "\n",
    "* Drop specified columns from the DataFrame:  \n",
    "  `df.drop(columns=['column1', 'column2'])`\n",
    "\n",
    "* Rename columns:  \n",
    "  `df.rename(columns={'old_name': 'new_name'})`\n",
    "\n",
    "* Replace NaN values with a specified value:  \n",
    "  `df.fillna(value, inplace=True)`\n",
    "\n",
    "* Check for null values in each column:  \n",
    "  `df.isnull().sum()`\n",
    "\n",
    "* Create a new column based on existing ones:  \n",
    "  `df['new_column'] = df['column1'] + df['column2']`\n",
    "\n",
    "* Update values in a new column based on a condition:  \n",
    "  `df.loc[df['column'] > value, 'new_column'] = 'value'`\n",
    "\n",
    "* Change the data type of a column:  \n",
    "  `df['column'].astype('int')`\n",
    "\n",
    "* Apply a function to each element in a column:  \n",
    "  `df['column'].apply(lambda x: x * 2)`\n",
    "\n",
    "* Create a pivot table:  \n",
    "  `df.pivot_table(index='column1', columns='column2', values='column3')`\n",
    "\n",
    "* Export DataFrame to a CSV file:  \n",
    "  `df.to_csv('filename.csv', index=False)`\n",
    "\n",
    "* Load a CSV file into a DataFrame:  \n",
    "  `pd.read_csv('filename.csv')`\n",
    "\n",
    "* Generate summary statistics for numerical columns:  \n",
    "  `df.describe()`\n",
    "\n",
    "* Count unique values in a column:  \n",
    "  `df['column'].value_counts()`\n",
    "\n",
    "* Randomly select 5 rows from the DataFrame:  \n",
    "  `df.sample(n=5)`\n",
    "\n",
    "* Display the first 10 rows of the DataFrame:  \n",
    "  `df.head(10)`\n",
    "\n",
    "* Display the last 10 rows of the DataFrame:  \n",
    "  `df.tail(10)`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PySpark Commands\n",
    "\n",
    "* **Select specific columns from a DataFrame:**  \n",
    "  `df.select(\"column1\", \"column2\")`  \n",
    "\n",
    "* **Filter rows based on a condition:**  \n",
    "  `df.filter(condition)`  \n",
    "\n",
    "* **Group by a column and count rows in each group:**  \n",
    "  `df.groupBy(\"column1\").count()`  \n",
    "\n",
    "* **Join two DataFrames on a column:**  \n",
    "  `df1.join(df2, df1.column == df2.column)`  \n",
    "\n",
    "* **Sort rows by a column in ascending order:**  \n",
    "  `df.orderBy(\"column\", ascending=True)`  \n",
    "\n",
    "* **Create or replace a temporary SQL view from a DataFrame:**  \n",
    "  `df.createOrReplaceTempView(\"view_name\")`  \n",
    "\n",
    "* **Run a SQL query on a temporary view:**  \n",
    "  `spark.sql(\"SELECT * FROM view_name WHERE condition\").show()`  \n",
    "\n",
    "* **Write a DataFrame to a table in overwrite mode:**  \n",
    "  `df.write.mode(\"overwrite\").saveAsTable(\"table_name\")`  \n",
    "\n",
    "* **Read a table into a DataFrame:**  \n",
    "  `df = spark.read.table(\"table_name\")`  \n",
    "\n",
    "* **Count the number of rows in a DataFrame:**  \n",
    "  `df.count()`  \n",
    "\n",
    "* **Remove duplicate rows based on specified columns:**  \n",
    "  `df.dropDuplicates([\"column1\", \"column2\"])`  \n",
    "\n",
    "* **Group by a column and compute the average of another column:**  \n",
    "  `df.groupBy(\"column1\").avg(\"column2\")`  \n",
    "\n",
    "* **Rename a column in the DataFrame:**  \n",
    "  `df.withColumnRenamed(\"column1\", \"new_column_name\")`  \n",
    "\n",
    "* **Limit the number of rows in the output:**  \n",
    "  `df.limit(10)`  \n",
    "\n",
    "* **Evaluate an expression (e.g., sum of a column):**  \n",
    "  `df.selectExpr(\"sum(column1)\").show()`  \n",
    "\n",
    "* **Drop specified columns from the DataFrame:**  \n",
    "  `df.drop(\"column1\", \"column2\")`  \n",
    "\n",
    "* **Filter rows where a column is null or not null:**  \n",
    "  `df.filter(df.column2.isNull()) / df.filter(df.column2.isNotNull())`  \n",
    "\n",
    "* **Filter rows where a column is greater than or equal to a value:**  \n",
    "  `df.filter(df.column >= value).show()`  \n",
    "\n",
    "* **Filter rows where a column's value is in a list of values:**  \n",
    "  `df.filter(df.column.isin(value1, value2)).show()`  \n",
    "\n",
    "* **Filter rows where a column's value falls between two values:**  \n",
    "  `df.filter(df.column.between(value1, value2)).show()`  \n",
    "\n",
    "* **Filter rows where a column's value matches a pattern:**  \n",
    "  `df.filter(df.column.like('pattern')).show()`  \n",
    "\n",
    "* **Cast a column to a specific data type:**  \n",
    "  `df.selectExpr(\"CAST(column AS data_type)\").show()`  \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
